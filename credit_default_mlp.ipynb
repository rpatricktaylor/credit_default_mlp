{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all the libraries ever\n",
    "import time as time\n",
    "\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import batch_norm, fully_connected, dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now = datetime.utcnow().strftime('%Y-%m-%d_%H%M%S')\n",
    "#root_logdir = 'tf_logs'\n",
    "#logdir = '{}/run-{}/'.format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data_dir = '/home/ryan/data/ccard_defaults/'\n",
    "\n",
    "data = pd.read_csv(data_dir + 'ccard_defaults.csv', index_col='ID')\n",
    "\n",
    "target = data.iloc[:, -1]\n",
    "data.drop('default payment next month', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>BILL_AMT2</th>\n",
       "      <th>BILL_AMT3</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>14027.0</td>\n",
       "      <td>13559.0</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46990.0</td>\n",
       "      <td>48233.0</td>\n",
       "      <td>49291.0</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>35835.0</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "ID                                                                         \n",
       "1     20000.0    2          2         1   24      2      2     -1     -1   \n",
       "2    120000.0    2          2         2   26     -1      2      0      0   \n",
       "3     90000.0    2          2         2   34      0      0      0      0   \n",
       "4     50000.0    2          2         1   37      0      0      0      0   \n",
       "5     50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "    PAY_5  PAY_6  BILL_AMT1  BILL_AMT2  BILL_AMT3  BILL_AMT4  BILL_AMT5  \\\n",
       "ID                                                                        \n",
       "1      -2     -2     3913.0     3102.0      689.0        0.0        0.0   \n",
       "2       0      2     2682.0     1725.0     2682.0     3272.0     3455.0   \n",
       "3       0      0    29239.0    14027.0    13559.0    14331.0    14948.0   \n",
       "4       0      0    46990.0    48233.0    49291.0    28314.0    28959.0   \n",
       "5       0      0     8617.0     5670.0    35835.0    20940.0    19146.0   \n",
       "\n",
       "    BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \n",
       "ID                                                                         \n",
       "1         0.0       0.0     689.0       0.0       0.0       0.0       0.0  \n",
       "2      3261.0       0.0    1000.0    1000.0    1000.0       0.0    2000.0  \n",
       "3     15549.0    1518.0    1500.0    1000.0    1000.0    1000.0    5000.0  \n",
       "4     29547.0    2000.0    2019.0    1200.0    1100.0    1069.0    1000.0  \n",
       "5     19131.0    2000.0   36681.0   10000.0    9000.0     689.0     679.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23364\n",
       "1     6636\n",
       "Name: default payment next month, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pay_cols = ['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "\n",
    "for col in pay_cols:\n",
    "    col_ord = data.loc[:, col].copy()\n",
    "    col_ord.loc[col_ord < 0] = 0\n",
    "    \n",
    "    col_cat = data.loc[:, col].copy()\n",
    "    col_cat.loc[col_cat > 0] = 1\n",
    "    \n",
    "    data[col + '_ORD'] = col_ord\n",
    "    data[col + '_CAT'] = col_cat\n",
    "    \n",
    "    data.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_cols = ['SEX',       'EDUCATION', 'MARRIAGE', \n",
    "            'PAY_0_CAT', 'PAY_2_CAT', 'PAY_3_CAT', \n",
    "            'PAY_4_CAT', 'PAY_5_CAT', 'PAY_6_CAT']\n",
    "num_cols = np.setdiff1d(list(data.columns), cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def name_to_pos(index, names):\n",
    "    index_lookup = {name : n for n, name in enumerate(index)}\n",
    "    return [index_lookup[name] for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_cols_pos = name_to_pos(data.columns, cat_cols)\n",
    "num_cols_pos = name_to_pos(data.columns, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 18, 20, 22, 24, 26, 28]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define some helper classes\n",
    "\n",
    "class ArrayColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attrs):\n",
    "        self.attrs = attrs\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[:, self.attrs]\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, labels=None):\n",
    "        self.encoders = []\n",
    "        self.labels = labels\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.encoders = []\n",
    "        for col in range(X.shape[1]):\n",
    "            le = LabelEncoder()\n",
    "            if self.labels:\n",
    "                le.fit(self.labels[col])\n",
    "            else:\n",
    "                le.fit(X[:, col])\n",
    "            self.encoders.append(le)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.encoders:\n",
    "            out = np.zeros([X.shape[0], 1])\n",
    "            for col, le in enumerate(self.encoders):\n",
    "                out = np.append(out, le.transform(X[:, col]).reshape((-1, 1)), axis=1)\n",
    "            return out[:, 1:]\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "cat_labels = [np.unique(data.iloc[:, col]) for col in cat_cols_pos]\n",
    "        \n",
    "numeric_pipeline = Pipeline([\n",
    "    ('selector', ArrayColumnSelector(num_cols_pos)),\n",
    "    ('principal_components', PCA(n_components=.9, svd_solver='full')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "categ_pipeline = Pipeline([\n",
    "    ('selector', ArrayColumnSelector(cat_cols_pos)),\n",
    "    ('label_encoder', MultiColumnLabelEncoder(cat_labels)),\n",
    "    ('onehot_encoder', OneHotEncoder())\n",
    "    ])\n",
    "\n",
    "preproc_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('numeric_pipeline', numeric_pipeline),\n",
    "    ('categ_pipeline', categ_pipeline)\n",
    "    ],\n",
    "    n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.values, target, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=49413,\n",
    "                                                    stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27000, 29)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = preproc_pipeline.fit_transform(X_train)\n",
    "X_test  = preproc_pipeline.transform(X_test)\n",
    "\n",
    "X_train = np.float32(X_train.toarray())\n",
    "X_test  = np.float32(X_test.toarray())\n",
    "\n",
    "y_train = np.int64(y_train)\n",
    "y_test = np.int64(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batch(epoch_num, batch_num, batch_size, n_batches, n_rows, X, y):\n",
    "    np.random.seed(epoch_num * n_batches + batch_num)\n",
    "    idx = np.random.choice(n_rows, batch_size, replace=False)\n",
    "    X_batch = X[idx, :]\n",
    "    y_batch = y[idx]\n",
    "    return X_batch, y_batch\n",
    "\n",
    "def mlp_accs(X_train, X_test, y_train, y_test, n_epochs, batch_size, learning_rate, \n",
    "             reg_param, keep_prob, decay, n_hidden1, n_hidden2, n_hidden3, n_hidden4,\n",
    "             activation1, activation2, activation3, activation4):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    rows_train, cols_train = X_train.shape\n",
    "\n",
    "    n_batches = int(np.ceil(rows_train / batch_size))\n",
    "    n_outputs = 2\n",
    "    \n",
    "    X = tf.placeholder(tf.float32, shape=(None, cols_train), name='X')\n",
    "    y = tf.placeholder(tf.int64,   shape=(None),             name='y')\n",
    "\n",
    "    is_training = tf.placeholder(tf.bool, shape=(), name='is_training')\n",
    "    bnorm_params = {'is_training': is_training,\n",
    "                    'decay': decay,\n",
    "                    'scale': True,\n",
    "                    'updates_collections': None}\n",
    "\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer(mode='FAN_AVG')\n",
    "    \n",
    "    with tf.contrib.framework.arg_scope([fully_connected],\n",
    "                                        normalizer_fn=batch_norm,\n",
    "                                        normalizer_params=bnorm_params,\n",
    "                                        weights_initializer=he_init,\n",
    "                                        weights_regularizer=tf.contrib.layers.l2_regularizer(scale=reg_param)):\n",
    "        hidden1 = fully_connected(X,            n_hidden1, activation_fn=activation1, scope='hidden1')\n",
    "        hidden1_drop = dropout(hidden1, keep_prob=keep_prob, is_training=is_training)\n",
    "\n",
    "        hidden2 = fully_connected(hidden1_drop, n_hidden2, activation_fn=activation2, scope='hidden2')\n",
    "        hidden2_drop = dropout(hidden2, keep_prob=keep_prob, is_training=is_training)\n",
    "\n",
    "        hidden3 = fully_connected(hidden2_drop, n_hidden3, activation_fn=activation3, scope='hidden3')\n",
    "        hidden3_drop = dropout(hidden3, keep_prob=keep_prob, is_training=is_training)\n",
    "\n",
    "        hidden4 = fully_connected(hidden3_drop, n_hidden4, activation_fn=activation4, scope='hidden4')\n",
    "        hidden4_drop = dropout(hidden4, keep_prob=keep_prob, is_training=is_training)\n",
    "\n",
    "        logits  = fully_connected(hidden4_drop, n_outputs, activation_fn=None,       scope='outputs')\n",
    "        \n",
    "    with tf.name_scope('loss'):\n",
    "        cross_ent = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "        base_loss = tf.reduce_mean(cross_ent, name='loss')\n",
    "        reg_loss  = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "        loss      = tf.add_n([base_loss] + reg_loss, name='loss')\n",
    "        \n",
    "    with tf.name_scope('train'):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "    \n",
    "    with tf.name_scope('eval'):\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            for batch in range(n_batches):\n",
    "                X_batch, y_batch = get_batch(epoch, batch, batch_size, n_batches, rows_train, X_train, y_train)\n",
    "                sess.run(training_op, feed_dict={X: X_batch, y: y_batch, is_training: True})\n",
    "            train_accs.append(1. - accuracy.eval(feed_dict={X: X_batch, y: y_batch, is_training: False}))\n",
    "            test_accs.append(1. - accuracy.eval(feed_dict={X: X_test,  y: y_test,  is_training: False}))\n",
    "        #if epoch % 100 == 0:\n",
    "        #    print('Epoch {:04d}\\n  Accuracy (Train): {:f}\\n  Accuracy (Test) : {:f}'.format(epoch, train_acc, test_acc))\n",
    "            \n",
    "    #test_acc  = accuracy.eval(feed_dict={X: X_test,  y: y_test,  is_training: False})\n",
    "    #print('\\n\\nFinal Accuracy (Test): {:f}'.format(test_acc))\n",
    "    \n",
    "        softmax_out_train = hidden4.eval(feed_dict={X: X_train, y: y_train, is_training: False})\n",
    "        softmax_out_test  = hidden4.eval(feed_dict={X: X_test,  y: y_test,  is_training: False})\n",
    "    \n",
    "    return train_accs, test_accs, softmax_out_train, softmax_out_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ledger():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inc = 0\n",
    "        self.hist = []\n",
    "        \n",
    "    def __call__(self, d, l, n):\n",
    "        self.hist.append((d, l, n))\n",
    "        print('{:04d}\\t{}'.format(self.inc, time.asctime()))\n",
    "        self.inc += 1\n",
    "        \n",
    "led = ledger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlp_objective(param_dict):\n",
    "    \n",
    "    n_epochs         = 250\n",
    "    batch_size       = int(param_dict['batch_size'])\n",
    "    n_hidden1        = int(param_dict['n_hidden1'])\n",
    "    n_hidden2        = int(param_dict['n_hidden2'])\n",
    "    n_hidden3        = int(param_dict['n_hidden3'])\n",
    "    n_hidden4        = int(param_dict['n_hidden4'])\n",
    "    learning_rate    = param_dict['learning_rate']\n",
    "    reg_param        = param_dict['reg_param']\n",
    "    keep_prob        = param_dict['keep_prob']\n",
    "    decay            = param_dict['decay']\n",
    "    activation1      = param_dict['activation1']\n",
    "    activation2      = param_dict['activation2']\n",
    "    activation3      = param_dict['activation3']\n",
    "    activation4      = param_dict['activation4']\n",
    "    \n",
    "    _, test_loss, _, _ = mlp_accs(X_train, X_test, y_train, y_test, \n",
    "                                  n_epochs, batch_size, learning_rate, \n",
    "                                  reg_param, keep_prob, decay, \n",
    "                                  n_hidden1, n_hidden2, n_hidden3, n_hidden4,\n",
    "                                  activation1, activation2, activation3, activation4)\n",
    "    \n",
    "    best_idx = np.argmin(test_loss)\n",
    "    loss = min(test_loss)\n",
    "    \n",
    "    led(d=param_dict, l=loss, n=best_idx)\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def objective(x):\n",
    "    return {'loss': mlp_objective(x),\n",
    "            'status': STATUS_OK,\n",
    "            'eval_time': time.time()}\n",
    "\n",
    "trials = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "space = {\n",
    "     'batch_size':    hp.quniform('batch_size',   200,  1000, 50),\n",
    "     'n_hidden1':     hp.quniform('n_hidden1',    200,  1000, 5),\n",
    "     'n_hidden2':     hp.quniform('n_hidden2',    200,  1000, 5),\n",
    "     'n_hidden3':     hp.quniform('n_hidden3',    200,  1000, 5),\n",
    "     'n_hidden4':     hp.quniform('n_hidden4',    200,  1000, 5),\n",
    "     'learning_rate': hp.uniform('learning_rate', 1e-5, 1e-2),\n",
    "     'reg_param':     hp.uniform('reg_param',     1e-5, 1e1),\n",
    "     'keep_prob':     hp.uniform('keep_prob',     0.4,  0.95),\n",
    "     'decay':         hp.uniform('decay',         0.9,  0.9999),\n",
    "     'activation1':   hp.choice('activation1',    [tf.nn.relu, tf.nn.elu, tf.nn.tanh, tf.sigmoid, tf.nn.softplus]),\n",
    "     'activation2':   hp.choice('activation2',    [tf.nn.relu, tf.nn.elu, tf.nn.tanh, tf.sigmoid, tf.nn.softplus]),\n",
    "     'activation3':   hp.choice('activation3',    [tf.nn.relu, tf.nn.elu, tf.nn.tanh, tf.sigmoid, tf.nn.softplus]),\n",
    "     'activation4':   hp.choice('activation4',    [tf.nn.relu, tf.nn.elu, tf.nn.tanh, tf.sigmoid, tf.nn.softplus])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000\tWed Jul 12 20:10:51 2017\n",
      "0001\tWed Jul 12 20:11:47 2017\n",
      "0002\tWed Jul 12 20:12:56 2017\n",
      "0003\tWed Jul 12 20:14:21 2017\n",
      "0004\tWed Jul 12 20:15:30 2017\n",
      "0005\tWed Jul 12 20:16:49 2017\n",
      "0006\tWed Jul 12 20:17:47 2017\n",
      "0007\tWed Jul 12 20:18:44 2017\n",
      "0008\tWed Jul 12 20:19:57 2017\n",
      "0009\tWed Jul 12 20:20:52 2017\n",
      "0010\tWed Jul 12 20:22:18 2017\n",
      "0011\tWed Jul 12 20:23:44 2017\n",
      "0012\tWed Jul 12 20:24:40 2017\n",
      "0013\tWed Jul 12 20:25:46 2017\n",
      "0014\tWed Jul 12 20:27:26 2017\n",
      "0015\tWed Jul 12 20:28:14 2017\n",
      "0016\tWed Jul 12 20:29:31 2017\n",
      "0017\tWed Jul 12 20:30:25 2017\n",
      "0018\tWed Jul 12 20:31:24 2017\n",
      "0019\tWed Jul 12 20:32:31 2017\n",
      "0020\tWed Jul 12 20:33:23 2017\n",
      "0021\tWed Jul 12 20:35:55 2017\n",
      "0022\tWed Jul 12 20:38:21 2017\n",
      "0023\tWed Jul 12 20:40:36 2017\n",
      "0024\tWed Jul 12 20:42:08 2017\n",
      "0025\tWed Jul 12 20:43:11 2017\n"
     ]
    }
   ],
   "source": [
    "led(None, None, None)\n",
    "\n",
    "best = fmin(fn=objective, \n",
    "            space=space, \n",
    "            algo=tpe.suggest, \n",
    "            max_evals=25,\n",
    "            trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation1': 4, 'activation2': 2, 'activation3': 1, 'activation4': 0, 'batch_size': 200.0, 'decay': 0.9404959259504099, 'keep_prob': 0.7441456645169185, 'learning_rate': 8.436449239381113e-05, 'n_hidden1': 585.0, 'n_hidden2': 835.0, 'n_hidden3': 370.0, 'n_hidden4': 410.0, 'reg_param': 0.07524309738417223}\n"
     ]
    }
   ],
   "source": [
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test, logits_train, logits_test = mlp_accs(X_train, X_test, y_train, y_test, \n",
    "                                                  296,  200,  8.4e-5, \n",
    "                                                  .075, .074, .94, \n",
    "                                                  585,  835,  370, 410,\n",
    "                                                  tf.nn.softplus, tf.nn.tanh, tf.nn.relu, tf.nn.elu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators = 100, max_depth=None)\n",
    "gbc.fit(logits_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - np.sum(gbc.predict(logits_test) == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
